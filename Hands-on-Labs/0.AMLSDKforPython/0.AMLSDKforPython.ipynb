{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Azure Machine Learning SDK for Python\n",
    "\n",
    "Sources from __[What is the Azure Machine Learning SDK for Python?](https://docs.microsoft.com/en-us/python/api/overview/azure/ml/?view=azure-ml-py)__\n",
    "\n",
    "Key areas of the SDK include:\n",
    "\n",
    "- Explore, prepare and manage the lifecycle of your datasets used in machine learning experiments.\n",
    "- Manage cloud resources for monitoring, logging, and organizing your machine learning experiments.\n",
    "- Train models either locally or by using cloud resources, including GPU-accelerated model training.\n",
    "- Use automated machine learning, which accepts configuration parameters and training data. It automatically iterates through algorithms and hyperparameter settings to find the best model for running predictions.\n",
    "- Deploy web services to convert your trained models into RESTful services that can be consumed in any application.\n",
    "\n",
    "\n",
    "AML SDK for Python Namespace:\n",
    "* Workspace\n",
    "* Dataset\n",
    "* Experiment\n",
    "* Run\n",
    "* Model\n",
    "* ComputeTarget\n",
    "* RunConfiguration\n",
    "* ScriptRunConfig\n",
    "* Environment\n",
    "* Pipeline\n",
    "* PythonScriptStep\n",
    "\n",
    "![AMLWorkspace](https://docs.microsoft.com/en-us/azure/machine-learning/media/concept-workspace/azure-machine-learning-taxonomy.png#lightbox)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check version of the SDK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import azureml.core\n",
    "\n",
    "\n",
    "print(\"Azure Machine Learning SDK for python version {0}\".format(azureml.core.VERSION))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Workspace\n",
    "\n",
    "### azureml.core.workspace.Workspace\n",
    "\n",
    "Create AML Workspace\n",
    "\n",
    "```python\n",
    "from azureml.core import Workspace\n",
    "ws = Workspace.create(name='myworkspace',\n",
    "           subscription_id='<azure-subscription-id>',\n",
    "           resource_group='myresourcegroup',\n",
    "           create_resource_group=True,\n",
    "           location='eastus2'\n",
    "           )\n",
    "```\n",
    "\n",
    "__Get workspace object__\n",
    "\n",
    "```python\n",
    "from azureml.core import Workspace\n",
    "\n",
    "ws = Workspace.get(name=\"myworkspace\",\n",
    "            subscription_id='<azure-subscription-id>',\n",
    "            resource_group='myresourcegroup')\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core import Workspace\n",
    "\n",
    "\n",
    "# Read from '.azureml/' in the current working directory and 'config.json' file\n",
    "ws = Workspace.from_config()\n",
    "\n",
    "ws.get_details()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fs = open('./.azureml/config.json')\n",
    "\n",
    "print(fs.read())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Datastore and DataSet\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "csvfile = 'diabetes.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core import Datastore\n",
    "\n",
    "datastore_name = 'workspaceblobstore' # Update the value with your datastore name\n",
    "\n",
    "# retrieve an existing datastore in the workspace by name\n",
    "datastore = Datastore.get(ws, datastore_name)\n",
    "datastore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_datastore = datastore.upload('./data', 'data', overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core import Dataset\n",
    "\n",
    "ds = Dataset.File.from_files(path=[(datastore,'./data/diabetes.csv')])\n",
    "ds.register(ws, 'diabetes', create_new_version=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment\n",
    "\n",
    "### azureml.core.experiment.Experiment\n",
    "\n",
    "The Experiment class is another foundational cloud resource that represents a collection of trials (individual model runs). The following code fetches an Experiment object from within Workspace by name, or it creates a new Experiment object if the name doesn't exist.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core.experiment import Experiment\n",
    "\n",
    "expName = \"mtc-aml-lab-exp\"\n",
    "exp = Experiment(workspace=ws, name=expName)\n",
    "exp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp.tag(\"projectName\",\"AML-Lab\")\n",
    "exp.tag(\"MTCLocation\",\"Seattle\")\n",
    "exp.tag(\"MTCTeam\",\"MTCS\")\n",
    "exp.tag(\"MTCTeam\",\"MTC Seattle\") # Careful, tags are mutable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "list_experiments = Experiment.list(ws)\n",
    "list_experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for experiment in list_experiments:\n",
    "    if experiment.name == expName:\n",
    "        print(experiment.name) \n",
    "        print(experiment.tags)\n",
    "\n",
    "# Check the value of key 'Team'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_runs = exp.get_runs()\n",
    "\n",
    "for run in list_runs:\n",
    "    print(run.id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are two ways to execute an experiment trial. \n",
    "\n",
    "If you're interactively experimenting in a Jupyter notebook, use the `start_logging` function. \n",
    "\n",
    "If you're submitting an experiment from a standard Python environment, use the `submit` function. \n",
    "\n",
    "Both functions return a Run object. The experiment variable represents an Experiment object in the following code examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run = exp.start_logging()\n",
    "run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_runs = exp.get_runs()\n",
    "\n",
    "for run in list_runs:\n",
    "    print(run)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run\n",
    "\n",
    "### azureml.core.run.Run\n",
    "\n",
    "A run represents a single trial of an experiment. Run is the object that you use to monitor the asynchronous execution of a trial, store the output of the trial, analyze results, and access generated artifacts. You use Run inside your experimentation code to log metrics and artifacts to the Run History service. Functionality includes:\n",
    "\n",
    "- Storing and retrieving metrics and data.\n",
    "- Using tags and the child hierarchy for easy lookup of past runs.\n",
    "- Registering stored model files for deployment.\n",
    "- Storing, modifying, and retrieving properties of a run.\n",
    "\n",
    "Create a Run object by submitting an Experiment object with a run configuration object. Use the tags parameter to attach custom categories and labels to your runs. You can easily find and retrieve them later from Experiment.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run = experiment.submit(config=your_config_object, tags=tags)\n",
    "\n",
    "run.tag(\"owner\",\"hyun\")\n",
    "run.tag(\"build\",\"dev\")\n",
    "run.tag(\"codeVersion\",1) # Integer or string for value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(run)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core.run import Run\n",
    "\n",
    "filtered_list_runs = Run.list(exp, tags={\"owner\":\"hyun\", \"build\":\"dev\"})\n",
    "\n",
    "for filtered_run in filtered_list_runs:\n",
    "    print(filtered_run)\n",
    "    print(filtered_run.tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_details = run.get_details()\n",
    "run_details"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Output for this function is a dictionary that includes:\n",
    "\n",
    "- Run ID\n",
    "- Status\n",
    "- Start and end time\n",
    "- Compute target (local versus cloud)\n",
    "- Dependencies and versions used in the run\n",
    "- Training-specific data (differs depending on model type)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Upload file/s to AML using RUN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run.upload_file(name='aml-lab/workshop.ipynb', path_or_stream=\"./0.AMLSDKforPython.ipynb\")\n",
    "\n",
    "# Go to 'Run' > 'Outputs + Logs' in Experiment of Azure Machine Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logging metrics using RUN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run.log_list(name='Fibonacci', value=[0, 1, 1, 2, 3, 5, 8, 13, 21, 34, 55, 89])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "for i in (range(-10, 10)): \n",
    "    run.log(name='Sigmoid', value=1 / (1 + np.exp(-i)))\n",
    "    angle = i / 2.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in (range(-10, 10)):\n",
    "    angle = i / 2.0\n",
    "    run.log_row(name='Cosine Wave', angle=angle, cos=np.cos(angle))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "citrus = ['orange', 'lemon', 'lime']\n",
    "sizes = [ 10, 7, 3]\n",
    "\n",
    "for index in range(len(citrus)):\n",
    "    run.log_row(\"citrus\", fruit = citrus[index], size=sizes[index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run.log_image(name='AML Concept Whiteboard', path='./AML_concept.png', plot=None, description='Discussion lead by Hyun at MTC Seattle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = run.get_metrics()\n",
    "# metrics is of type Dict[str, List[float]] mapping metric names\n",
    "# to a list of the values for that metric in the given run.\n",
    "\n",
    "print(metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run.complete()\n",
    "# run.cancel()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model\n",
    "\n",
    "### azureml.core.model.Model\n",
    "\n",
    "The `Model` class is used for working with cloud representations of machine learning models. Methods help you transfer models between local development environments and the `Workspace` object in the cloud.\n",
    "\n",
    "You can use model registration to store and version your models in the Azure cloud, in your workspace. Registered models are identified by name and version. Each time you register a model with the same name as an existing one, the registry increments the version. Azure Machine Learning supports any model that can be loaded through Python 3, not just Azure Machine Learning models.\n",
    "\n",
    "The following example shows how to build a simple local classification model with `scikit-learn`, register the model in `Workspace`, and download the model from the cloud.\n",
    "\n",
    "Create a simple classifier, `clf`, to predict customer churn based on their age. Then dump the model to a `.pkl` file in the same directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "import joblib\n",
    "import numpy as np\n",
    "\n",
    "# customer ages\n",
    "X_train = np.array([50, 17, 35, 23, 28, 40, 31, 29, 19, 62])\n",
    "X_train = X_train.reshape(-1, 1)\n",
    "# churn y/n\n",
    "y_train = [\"yes\", \"no\", \"no\", \"no\", \"yes\", \"yes\", \"yes\", \"no\", \"no\", \"yes\"]\n",
    "\n",
    "clf = svm.SVC(gamma=0.001, C=100.)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "joblib.dump(value=clf, filename=\"churn-model.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the `register` function to register the model in your workspace. Specify the local model path and the model name. Registering the same name more than once will create a new version."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core.model import Model\n",
    "\n",
    "model = Model.register(workspace=ws,\n",
    "                       model_path=\"churn-model.pkl\",\n",
    "                       model_name=\"churn-model-test\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that the model is registered in your workspace, it's easy to manage, download, and organize your models. To retrieve a model (for example, in another environment) object from `Workspace`, use the class constructor and specify the model name and any optional parameters. Then, use the download function to `download` the model, including the cloud folder structure."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Environment\n",
    "\n",
    "### azureml.core.environment.Environment\n",
    "\n",
    "Azure Machine Learning environments specify the Python packages, environment variables, and software settings around your training and scoring scripts. In addition to Python, you can also configure PySpark, Docker and R for environments. Internally, environments result in Docker images that are used to run the training and scoring processes on the compute target. The environments are managed and versioned entities within your Machine Learning workspace that enable reproducible, auditable, and portable machine learning workflows across a variety of compute targets and compute types.\n",
    "\n",
    "You can use an Environment object to:\n",
    "\n",
    "- Develop your training script.\n",
    "- Reuse the same environment on Azure Machine Learning Compute for model training at scale.\n",
    "- Deploy your model with that same environment without being tied to a specific compute type.\n",
    "\n",
    "The following code imports the Environment class from the SDK and to instantiates an environment object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from azureml.core.environment import Environment\n",
    "from azureml.core.conda_dependencies import CondaDependencies\n",
    "\n",
    "# pyVersion = f\"{sys.version_info.major}.{sys.version_info.minor}.{sys.version_info.micro}\"\n",
    "computeInstanceName = '' # <update the value with your Compute Instance Name>\n",
    "\n",
    "myenv = Environment(name=\"myEnv\")\n",
    "conda_dep = CondaDependencies()\n",
    "\n",
    "# Installs pillow package\n",
    "conda_dep.add_conda_package(\"numpy==1.17.0\")\n",
    "conda_dep.add_pip_package(\"scikit-learn\")\n",
    "conda_dep.add_pip_package(\"pillow\")\n",
    "conda_dep.add_pip_package(\"azureml-dataprep[pandas]\")\n",
    "\n",
    "\n",
    "# Adds dependencies to PythonSection of myenv\n",
    "myenv.python.conda_dependencies=conda_dep\n",
    "myenv.python.conda_dependencies.set_python_version(\"3.6\")\n",
    "myenv.register(ws)\n",
    "myenv.build(ws, computeInstanceName)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core.model import Model\n",
    "import os\n",
    "\n",
    "model = Model(workspace=ws, name=\"churn-model-test\")\n",
    "model.download(target_dir=os.path.join(os.getcwd(),\"myDownload\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ComputeTarget\n",
    "\n",
    "### azureml.core.compute.ComputeTarget\n",
    "\n",
    "The `ComputeTarget` class is the abstract parent class for creating and managing compute targets. A compute target represents a variety of resources where you can train your machine learning models. A compute target can be either a local machine or a cloud resource, such as Azure Machine Learning Compute, Azure HDInsight, or a remote virtual machine.\n",
    "\n",
    "Use compute targets to take advantage of powerful virtual machines for model training, and set up either persistent compute targets or temporary runtime-invoked targets. For a comprehensive guide on setting up and managing compute targets, see the how-to.\n",
    "\n",
    "The following code shows a simple example of setting up an `ComputeInstance` target. The resource scales automatically when a job is submitted. It's deleted automatically when the run finishes.\n",
    "\n",
    "Reuse the simple scikit-learn churn model and build it into its own file, train.py, in the current directory. At the end of the file, create a new directory called outputs. This step creates a directory in the cloud (your workspace) to store your trained model that joblib.dump() serialized."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core.compute import ComputeInstance \n",
    "\n",
    "computeInstanceName = ''\n",
    "myInstance = ComputeInstance(ws, computeInstanceName)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RunConfiguration\n",
    "\n",
    "### azureml.core.compute.RunConfiguration\n",
    "\n",
    "Next you create the compute target by instantiating a RunConfiguration object and setting the type and size. This example uses the smallest resource size (1 CPU core, 3.5 GB of memory). The list_vms variable contains a list of supported virtual machines and their sizes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core.runconfig import RunConfiguration\n",
    "\n",
    "compute_config = RunConfiguration()\n",
    "compute_config.target = myInstance\n",
    "compute_config"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core.conda_dependencies import CondaDependencies\n",
    "\n",
    "dependencies = CondaDependencies()\n",
    "dependencies.add_pip_package(\"scikit-learn\")\n",
    "dependencies.add_pip_package(\"numpy==1.15.4\")\n",
    "\n",
    "compute_config.environment.python.conda_dependencies = dependencies\n",
    "compute_config.environment = myenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile ./source/train/train.py\n",
    "from sklearn import svm\n",
    "import numpy as np\n",
    "import joblib\n",
    "import os\n",
    "\n",
    "# customer ages\n",
    "X_train = np.array([50, 17, 35, 23, 28, 40, 31, 29, 19, 62])\n",
    "X_train = X_train.reshape(-1, 1)\n",
    "# churn y/n\n",
    "y_train = [\"yes\", \"no\", \"no\", \"no\", \"yes\", \"yes\", \"yes\", \"no\", \"no\", \"yes\"]\n",
    "\n",
    "clf = svm.SVC(gamma=0.001, C=100.)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "os.makedirs(\"outputs\", exist_ok=True)\n",
    "joblib.dump(value=clf, filename=\"outputs/churn-model.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core.experiment import Experiment\n",
    "from azureml.core import ScriptRunConfig\n",
    "\n",
    "script_run_config = ScriptRunConfig(\n",
    "    source_directory=\"./source/train\",\n",
    "    script=\"train.py\",\n",
    "    run_config=compute_config)\n",
    "\n",
    "experiment = Experiment(workspace=ws, name=expName)\n",
    "\n",
    "run = experiment.submit(config=script_run_config)\n",
    "\n",
    "# This may take around 7 minutes\n",
    "run.wait_for_completion(show_output=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> TIP\n",
    "> [Prep your code for production](https://docs.microsoft.com/en-us/azure/machine-learning/tutorial-convert-ml-experiment-to-production)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ScriptRunConfig\n",
    "\n",
    "### azureml.core.script_run_config.ScriptRunConfig\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core.experiment import Experiment\n",
    "from azureml.core import ScriptRunConfig\n",
    "\n",
    "runconfig = ScriptRunConfig(\n",
    "    source_directory=\"./source/train\",\n",
    "    script=\"train.py\")\n",
    "\n",
    "# Attach compute target to run config\n",
    "runconfig.run_config.target = \"local\"\n",
    "\n",
    "# Attach environment to run config\n",
    "runconfig.run_config.environment = myenv\n",
    "\n",
    "experiment = Experiment(workspace=ws, name=expName)\n",
    "\n",
    "run = experiment.submit(config=script_run_config)\n",
    "\n",
    "run.wait_for_completion(show_output=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pipeline, PythonScriptStep\n",
    "\n",
    "### azureml.pipeline.core.pipeline.Pipeline\n",
    "### azureml.pipeline.steps.python_script_step.PythonScriptStep\n",
    "\n",
    "\n",
    "An Azure Machine Learning pipeline is an automated workflow of a complete machine learning task. Subtasks are encapsulated as a series of steps within the pipeline. An Azure Machine Learning pipeline can be as simple as one step that calls a Python script. Pipelines include functionality for:\n",
    "\n",
    "- Data preparation including importing, validating and cleaning, munging and transformation, normalization, and staging\n",
    "- Training configuration including parameterizing arguments, filepaths, and logging / reporting configurations\n",
    "- Training and validating efficiently and repeatably, which might include specifying specific data subsets, different hardware compute resources, distributed processing, and progress monitoring\n",
    "- Deployment, including versioning, scaling, provisioning, and access control\n",
    "- Publishing a pipeline to a REST endpoint to rerun from any HTTP library\n",
    "\n",
    "A ```PythonScriptStep``` is a basic, built-in step to run a Python Script on a compute target. It takes a script name and other optional parameters like arguments for the script, compute target, inputs and outputs. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pattern for creating and using ML Pipeline\n",
    "\n",
    "An Azure Machine Learning pipeline is associated with an Azure Machine Learning workspace and a pipeline step is associated with a compute target available within that workspace. For more information, see this article about workspaces or this explanation of compute targets.\n",
    "\n",
    "A common pattern for pipeline steps is:\n",
    "\n",
    "1. Specify workspace, compute, and storage\n",
    "2. Configure your input and output data using\n",
    "    1. Dataset which makes available an existing Azure datastore\n",
    "    2. PipelineDataset which encapsulates typed tabular data\n",
    "    3. PipelineData which is used for intermediate file or directory data written by one step and intended to be consumed by another\n",
    "3. Define one or more pipeline steps\n",
    "4. Instantiate a pipeline using your workspace and steps\n",
    "5. Create an experiment to which you submit the pipeline\n",
    "6. Monitor the experiment results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core.dataset import Dataset\n",
    "\n",
    "web_path ='https://dprepdata.blob.core.windows.net/demo/Titanic.csv'\n",
    "titanic_ds = Dataset.Tabular.from_delimited_files(path=web_path)\n",
    "titanic_ds.register(ws, 'titanic', create_new_version=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile ./source/prepdata/prepare.py\n",
    "\n",
    "import os\n",
    "import argparse\n",
    "from azureml.core import Dataset, Run\n",
    "\n",
    "parser = argparse.ArgumentParser(\"prep\")\n",
    "\n",
    "parser.add_argument(\"--output_path\", type=str, help=\"output data directory\")\n",
    "\n",
    "args = parser.parse_args()\n",
    "\n",
    "print(os.environ)\n",
    "\n",
    "run = Run.get_context()\n",
    "ws = run.experiment.workspace\n",
    "\n",
    "dataset = run.input_datasets['titanic']\n",
    "df = dataset.to_pandas_dataframe()\n",
    "df = df.drop(labels=['PassengerId', 'Name', 'Ticket', 'Fare', 'Embarked'], axis=1)\n",
    "\n",
    "print(df)\n",
    "\n",
    "os.makedirs(args.output_path)\n",
    "df.to_csv(os.path.join(args.output_path, 'prepdTitanic.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core import Dataset, RunConfiguration\n",
    "from azureml.pipeline.steps import PythonScriptStep\n",
    "from azureml.pipeline.core import Pipeline, PipelineData\n",
    "\n",
    "# get input dataset\n",
    "input_ds = Dataset.get_by_name(ws, 'titanic')\n",
    "\n",
    "# register pipeline output as dataset\n",
    "output_ds = PipelineData('prepared_titanic_ds', datastore=datastore).as_dataset()\n",
    "output_ds = output_ds.register(name='prepared_titanic', create_new_version=True)\n",
    "\n",
    "# configure for runconfig\n",
    "runconfig = RunConfiguration()\n",
    "runconfig.environment = myenv\n",
    "\n",
    "# configure pipeline step to use dataset as the input and output\n",
    "prep_step = PythonScriptStep(script_name=\"prepare.py\",\n",
    "                             arguments=[\"--output_path\",output_ds],\n",
    "                             inputs=[input_ds.as_named_input('titanic')],\n",
    "                             outputs=[output_ds],\n",
    "                             compute_target=compute_target,\n",
    "                             source_directory=\"./source/prepdata\",\n",
    "                             runconfig=runconfig)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.pipeline.core import Pipeline\n",
    "\n",
    "pipeline = Pipeline(workspace=ws, steps=[prep_step])\n",
    "pipeline_run = exp.submit(pipeline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#End of notebook"
   ]
  }
 ],
 "metadata": {
  "kernel_info": {
   "name": "python38-azureml"
  },
  "kernelspec": {
   "display_name": "Python 3.8 - AzureML",
   "language": "python",
   "name": "python38-azureml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  },
  "nteract": {
   "version": "nteract-front-end@1.0.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
